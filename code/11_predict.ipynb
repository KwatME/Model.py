{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:49.777639Z",
     "start_time": "2018-07-06T07:59:49.765242Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T02:00:18.306031Z",
     "start_time": "2018-07-08T02:00:18.276698Z"
    }
   },
   "outputs": [],
   "source": [
    "from environment import *\n",
    "\n",
    "import setting_for_tcga as setting_0\n",
    "\n",
    "import setting_for_ccle as setting_1\n",
    "\n",
    "title = '{}<br>on<br>{}'.format(\n",
    "    setting_1.NAME,\n",
    "    setting_0.NAME,\n",
    ")\n",
    "\n",
    "print(title)\n",
    "\n",
    "path_dict_0 = path(setting_0)\n",
    "\n",
    "path_dict_1 = path(setting_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:51.551921Z",
     "start_time": "2018-07-06T07:59:51.522383Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_x_sample_0 = pd.read_table(\n",
    "    path_dict_0['feature_x_sample_file_path'],\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "gps_map_0 = ccal.load_gps_map(path_dict_0['gps_map_file_path'])\n",
    "\n",
    "w_0 = pd.DataFrame(\n",
    "    gps_map_0.wt.T,\n",
    "    index=gps_map_0.wt_elements,\n",
    "    columns=gps_map_0.nodes,\n",
    ")\n",
    "\n",
    "h_0 = pd.DataFrame(\n",
    "    gps_map_0.h,\n",
    "    index=gps_map_0.nodes,\n",
    "    columns=gps_map_0.h_elements,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x_sample_1 = ccal.read_and_process_feature_x_sample(\n",
    "    setting_1.FEATURE_X_SAMPLE_FILE_PATH,\n",
    "    nanize=setting_0.NANIZE,\n",
    "    drop_na_axis=setting_0.DROP_NA_AXIS,\n",
    "    min_n_not_na_unique_value=setting_0.MIN_N_NOT_NA_UNIQUE_VALUE,\n",
    "    max_na=setting_0.MAX_NA,\n",
    "    shift_as_necessary_to_achieve_min_before_logging=setting_0.SHIFT_AS_NECESSARY_BEFORE_LOGGING,\n",
    "    log_base=setting_0.LOG_BASE,\n",
    "    normalization_axis=setting_0.NORMALIZATION_AXIS,\n",
    "    normalization_method=setting_0.NORMALIZATION_METHOD,\n",
    "    max_plot_n=setting_0.MAX_PLOT_N,\n",
    "    plot=False,\n",
    ")\n",
    "\n",
    "feature_x_sample_1 = feature_x_sample_1.loc[w_0.index.str.lstrip('(-+) ').unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_matrix_1 = np.full(\n",
    "    (\n",
    "        w_0.shape[0],\n",
    "        feature_x_sample_1.shape[1],\n",
    "    ),\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "feature_skew_t_pdf_fit_parameter_0 = pd.read_table(\n",
    "    path_dict_0['feature_skew_t_pdf_fit_parameter_file_path'],\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "n = w_0.shape[0]\n",
    "\n",
    "n_per_print =  n // 10\n",
    "\n",
    "for i, sign_feature in enumerate(w_0.index):\n",
    "    \n",
    "    if i % n_per_print == 0:\n",
    "        \n",
    "        print('{}/{} ...'.format(\n",
    "            i,\n",
    "            n,\n",
    "        ))\n",
    "    \n",
    "    sign, feature = sign_feature.split()\n",
    "    \n",
    "    location_0, scale_0, degree_of_freedom_0, shape_0 = feature_skew_t_pdf_fit_parameter_0.loc[feature, [\n",
    "        'Location',\n",
    "        'Scale',\n",
    "        'Degree of Freedom',\n",
    "        'Shape',\n",
    "    ]]\n",
    "\n",
    "    context_dict_0 = ccal.compute_context(\n",
    "        feature_x_sample_0.loc[feature].values,\n",
    "        location=location_0,\n",
    "        scale=scale_0,\n",
    "        degree_of_freedom=degree_of_freedom_0,\n",
    "        shape=shape_0,\n",
    "        scale_with_kl=setting_0.SCALE_WITH_KL,\n",
    "    )\n",
    "    \n",
    "    grid_0 = context_dict_0['grid']\n",
    "\n",
    "    context_indices_0 = context_dict_0['context_indices']\n",
    "    \n",
    "    if sign == '(-)':\n",
    "\n",
    "        context_indices_0 = -context_indices_0.clip(max=0)\n",
    "    \n",
    "    elif sign == '(+)':\n",
    "        \n",
    "        context_indices_0 = context_indices_0.clip(min=0)\n",
    "        \n",
    "#     training__context_indices = ccal.normalize_nd_array(\n",
    "#         context_indices_0,\n",
    "#         None,\n",
    "#         '0-1',\n",
    "#     )\n",
    "\n",
    "    feature_values_1 = feature_x_sample_1.loc[feature].values\n",
    "\n",
    "    not_nan_1 = ~np.isnan(feature_values_1)\n",
    "\n",
    "    signal_matrix_1[i][not_nan_1] = context_indices_0[[np.absolute(grid_0 - value).argmin() for value in feature_values_1[not_nan_1]]]\n",
    "\n",
    "signal_matrix_1 = pd.DataFrame(\n",
    "    signal_matrix_1, \n",
    "    index=w_0.index,\n",
    "    columns=feature_x_sample_1.columns,\n",
    ")\n",
    "\n",
    "for sign_feature in np.random.choice(\n",
    "    signal_matrix_1.index,\n",
    "    size=16,\n",
    "    replace=False,\n",
    "):\n",
    "\n",
    "    sign, feature = sign_feature.split()\n",
    "    \n",
    "    feature_values_1 = feature_x_sample_1.loc[feature].sort_values()\n",
    "    \n",
    "    feature_signals_1 = signal_matrix_1.loc[sign_feature, feature_values_1.index]\n",
    "\n",
    "    ccal.plot_context(\n",
    "        feature_x_sample_0.loc[feature],\n",
    "        scale_with_kl=setting_0.SCALE_WITH_KL,\n",
    "        title=sign_feature,\n",
    "    )\n",
    "\n",
    "    ccal.plot_points(\n",
    "        ('Look Up Context', ),\n",
    "        (feature_values_1, ),\n",
    "        (feature_signals_1, ),\n",
    "        texts=(feature_values_1.index, ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_power = setting_0.GPS_MAP_H_PULL_POWER\n",
    "\n",
    "element_marker_size = setting_0.GPS_MAP_H_ELEMENT_MARKER_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:52.556033Z",
     "start_time": "2018-07-06T07:59:52.348450Z"
    }
   },
   "outputs": [],
   "source": [
    "a_1 = signal_matrix_1.fillna(0)\n",
    "\n",
    "h_1 = ccal.solve_for_nmf_h(\n",
    "    a_1,\n",
    "    w_0,\n",
    "#     pd.DataFrame(\n",
    "#         ccal.normalize_nd_array(\n",
    "#             w_0.values,\n",
    "#             0,\n",
    "#             'sum',\n",
    "#         ),\n",
    "#         index=w_0.index,\n",
    "#         columns=w_0.columns,\n",
    "#     ),\n",
    "    method='nnls',\n",
    ")\n",
    "\n",
    "h_element_states_1 = gps_map_0.predict(\n",
    "    'h',\n",
    "    h_1,\n",
    "    pull_power=pull_power,\n",
    "    title=title,\n",
    "    element_marker_size=element_marker_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:52.556033Z",
     "start_time": "2018-07-06T07:59:52.348450Z"
    }
   },
   "outputs": [],
   "source": [
    "ccal.plot_heat_map(\n",
    "    h_1,\n",
    "    normalization_axis=0,\n",
    "    normalization_method='-0-',\n",
    "    column_annotation=h_element_states_1,\n",
    "    cluster_axis=1,\n",
    "    title=title,\n",
    "    xaxis_title=h_1.columns.name,\n",
    "    yaxis_title=h_1.index.name,\n",
    ")\n",
    "\n",
    "\n",
    "ccal.make_comparison_panel(\n",
    "    h_1,\n",
    "    h_1,\n",
    "    name_0='Predicted',\n",
    "    name_1='Predicted',\n",
    ")\n",
    "\n",
    "known = pd.read_table(\n",
    "        path_dict_1['h_file_path'],\n",
    "        index_col=0,\n",
    "    )\n",
    "\n",
    "ccal.make_comparison_panel(\n",
    "    h_1,\n",
    "    known,\n",
    "    name_0='Predicted',\n",
    "    name_1='Known',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dicts_1 = setting_1.make_feature_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dicts_1_ = {feature_group: feature_dict for feature_group, feature_dict in feature_dicts_1.items() if feature_group in (\n",
    "    'NP24 Compound',\n",
    "    'CTRP Compound',\n",
    "    'Achilles RNAi',\n",
    "    'Achilles CRISPR',\n",
    ")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_x_sample = ccal.make_membership_df_from_categorical_series(pd.read_table(\n",
    "    path_dict_1['h_hcc__k_x_column_file_path'],\n",
    "    index_col=0,\n",
    ").loc['K{}'.format(setting_1.H_HCC_K)])\n",
    "\n",
    "state_x_sample.index = ('S{}'.format(i) for i in state_x_sample.index)\n",
    "\n",
    "feature_dicts_1_['State (original)'] = {\n",
    "    'df': state_x_sample,\n",
    "    'data_type': 'binary',\n",
    "    'emphasis':'high',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ccal.make_membership_df_from_categorical_series(h_element_states_1)\n",
    "\n",
    "targets.index = ('S{}'.format(i) for i in targets.index)\n",
    "\n",
    "n_target = targets.shape[0]\n",
    "\n",
    "ccal.make_match_panels(\n",
    "    (targets.iloc[i] for i in range(n_target)),\n",
    "    (\n",
    "        False,\n",
    "    ) * n_target,\n",
    "    (\n",
    "        False,\n",
    "    ) * n_target,\n",
    "    (\n",
    "        'binary',\n",
    "    ) * n_target,\n",
    "    feature_dicts_1_,\n",
    "    n_job=setting_0.MAX_N_JOB,\n",
    "    n_required_for_match_function=targets.shape[1] * 0.5,\n",
    "    extreme_feature_threshold=setting_0.EXTREME_FEATURE_THRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_highlight_1 = make_features_to_highlight()\n",
    "\n",
    "features_to_highlight_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_group, features in features_to_highlight_1.items():\n",
    "    \n",
    "    if feature_group in feature_dicts_1:\n",
    "        \n",
    "        df = feature_dicts_1[feature_group]['df']\n",
    "        \n",
    "        annotation_type = feature_dicts_1[feature_group]['data_type']\n",
    "\n",
    "        for feature in features:\n",
    "            \n",
    "            if feature in df.index:\n",
    "\n",
    "                h_1_element_states = gps_map_0.predict(\n",
    "                    'h',\n",
    "                    h_1,\n",
    "                    pull_power=pull_power,\n",
    "                    annotation_x_element=df.loc[feature].to_frame().T,\n",
    "                    annotation_std_maxs=(3, ),\n",
    "                    annotation_types=(annotation_type, ),\n",
    "                    title='{}<br>{}'.format(\n",
    "                        feature_group,\n",
    "                        feature,\n",
    "                    ),\n",
    "                    element_marker_size=element_marker_size,\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
