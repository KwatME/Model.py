{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:49.777639Z",
     "start_time": "2018-07-06T07:59:49.765242Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import *\n",
    "\n",
    "with open(\"setting.yaml\") as yaml_file:\n",
    "\n",
    "    SETTING = yaml.load(yaml_file)\n",
    "\n",
    "PATH = make_path_dict(SETTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:51.551921Z",
     "start_time": "2018-07-06T07:59:51.522383Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_x_sample_processed_0 = pd.read_csv(\n",
    "    PATH[\"feature_x_sample.processed.tsv\"], sep=\"\\t\", index_col=0\n",
    ")\n",
    "\n",
    "feature_x_sample_processed_0.columns.name = SETTING[\"sample_alias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:51.551921Z",
     "start_time": "2018-07-06T07:59:51.522383Z"
    }
   },
   "outputs": [],
   "source": [
    "w_0 = pd.read_csv(PATH[\"w.tsv\"], sep=\"\\t\", index_col=0)\n",
    "\n",
    "w_0.columns.name = \"Factor\"\n",
    "\n",
    "h_0 = pd.read_csv(PATH[\"h.tsv\"], sep=\"\\t\", index_col=0)\n",
    "\n",
    "h_0.columns.name = feature_x_sample_processed_0.columns.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:51.551921Z",
     "start_time": "2018-07-06T07:59:51.522383Z"
    }
   },
   "outputs": [],
   "source": [
    "gps_map_0 = ccal.read_gps_map(PATH[\"gps_map.pickle.gz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x_sample_1 = pd.read_csv(\n",
    "    SETTING[\"new_feature_x_sample_file_path\"], sep=\"\\t\", index_col=0\n",
    ")\n",
    "\n",
    "feature_x_sample_1.index.name = feature_x_sample_processed_0.index.name\n",
    "\n",
    "feature_x_sample_1.columns.name = SETTING[\"new_sample_alias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x_sample_processed_1 = ccal.process_feature_x_sample(\n",
    "    feature_x_sample_1,\n",
    "    shift_as_necessary_to_achieve_min_before_logging=SETTING[\n",
    "        \"new_shift_as_necessary_to_achieve_min_before_logging\"\n",
    "    ],\n",
    "    log_base=SETTING[\"new_log_base\"],\n",
    "    normalization_axis=SETTING[\"new_normalization_axis\"],\n",
    "    normalization_method=SETTING[\"new_normalization_method\"],\n",
    "    clip_min=SETTING[\"new_clip_min\"],\n",
    "    clip_max=SETTING[\"new_clip_max\"],\n",
    "    feature_x_sample_alias=SETTING[\"new_feature_x_sample_alias\"],\n",
    "    feature_x_sample_value_name=SETTING[\"feature_x_sample_value_name\"],\n",
    "    plot_heat_map_max_size=SETTING[\"plot_heat_map_max_size\"],\n",
    "    plot_histogram_max_size=SETTING[\"plot_histogram_max_size\"],\n",
    "    plot_rug_max_size=SETTING[\"plot_rug_max_size\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x_sample_processed_1 = feature_x_sample_processed_1.reindex(\n",
    "    index=pd.Index(\n",
    "        set(feature.replace(\"(-) \", \"\").replace(\"(+) \", \"\") for feature in w_0.index),\n",
    "        name=w_0.index.name,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_features = ccal.select_series_indices(\n",
    "    feature_x_sample_processed_1.apply(\n",
    "        lambda feature_values: abs(\n",
    "            feature_values.median()\n",
    "            - feature_x_sample_processed_0.loc[feature_values.name].median()\n",
    "        ),\n",
    "        axis=1,\n",
    "    ),\n",
    "    \">\",\n",
    "    fraction=SETTING[\"new_inconsistent_feature_fraction_to_drop\"],\n",
    "    title={\"text\": \"Ranking of Feature Median Difference\"},\n",
    "    xaxis={\"title\": \"Rank\"},\n",
    "    yaxis={\"title\": \"Feature Median Difference\"},\n",
    ").tolist()\n",
    "\n",
    "extend = []\n",
    "\n",
    "for inconsistent_feature in inconsistent_features:\n",
    "\n",
    "    for template in (\"(-) {}\", \"(+) {}\"):\n",
    "\n",
    "        extend.append(template.format(inconsistent_feature))\n",
    "\n",
    "inconsistent_features += extend\n",
    "\n",
    "w_0.drop(w_0.index & inconsistent_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x_sample_signal_1 = pd.DataFrame(\n",
    "    index=w_0.index, columns=feature_x_sample_processed_1.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x_fit_parameter_0 = pd.read_csv(\n",
    "    PATH[\"feature_x_fit_parameter.tsv\"], sep=\"\\t\", index_col=0\n",
    ")\n",
    "\n",
    "n = w_0.shape[0]\n",
    "\n",
    "n_per_print = n // 10\n",
    "\n",
    "for i, sign_feature in enumerate(w_0.index):\n",
    "\n",
    "    if i % n_per_print == 0:\n",
    "\n",
    "        print(\"{}/{} ...\".format(i + 1, n))\n",
    "\n",
    "    sign, feature = sign_feature.split()\n",
    "\n",
    "    n_data_0, location_0, scale_0, degree_of_freedom_0, shape_0 = feature_x_fit_parameter_0.loc[\n",
    "        feature\n",
    "    ]\n",
    "\n",
    "    context_dict_0 = ccal.compute_1d_array_context(\n",
    "        feature_x_sample_processed_0.loc[feature].values,\n",
    "        n_data=n_data_0,\n",
    "        location=location_0,\n",
    "        scale=scale_0,\n",
    "        degree_of_freedom=degree_of_freedom_0,\n",
    "        shape=shape_0,\n",
    "    )\n",
    "\n",
    "    grid_0 = context_dict_0[\"grid\"]\n",
    "\n",
    "    context_indices_0 = context_dict_0[\"context\"]\n",
    "\n",
    "    if sign == \"(-)\":\n",
    "\n",
    "        signals_0 = -context_indices_0.clip(max=0)\n",
    "\n",
    "    elif sign == \"(+)\":\n",
    "\n",
    "        signals_0 = context_indices_0.clip(min=0)\n",
    "\n",
    "        signals_0 = ccal.normalize_nd_array(\n",
    "            signals_0, None, SETTING[\"signal_normalization_method\"], raise_for_bad=False\n",
    "        )\n",
    "\n",
    "    values_1 = feature_x_sample_processed_1.loc[feature].values\n",
    "\n",
    "    is_good_1 = ~ccal.check_nd_array_for_bad(values_1, raise_for_bad=False)\n",
    "\n",
    "    feature_x_sample_signal_1.iloc[i, is_good_1] = signals_0[\n",
    "        [np.absolute(value_1 - grid_0).argmin() for value_1 in values_1[is_good_1]]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sign_feature in np.random.choice(\n",
    "    feature_x_sample_signal_1.index, size=8, replace=False\n",
    "):\n",
    "\n",
    "    feature = sign_feature.split()[1]\n",
    "\n",
    "    n_data_0, location_0, scale_0, degree_of_freedom_0, shape_0 = feature_x_fit_parameter_0.loc[\n",
    "        feature\n",
    "    ]\n",
    "\n",
    "    ccal.plot_context(\n",
    "        feature_x_sample_processed_0.loc[feature],\n",
    "        n_data=n_data_0,\n",
    "        location=location_0,\n",
    "        scale=scale_0,\n",
    "        degree_of_freedom=degree_of_freedom_0,\n",
    "        shape=shape_0,\n",
    "        title=sign_feature,\n",
    "    )\n",
    "\n",
    "    values_1 = feature_x_sample_processed_1.loc[feature].sort_values()\n",
    "\n",
    "    ccal.plot_and_save(\n",
    "        {\n",
    "            \"layout\": {\"title\": {\"text\": \"{} (new)\".format(sign_feature)}},\n",
    "            \"data\": [\n",
    "                {\n",
    "                    \"type\": \"scatter\",\n",
    "                    \"x\": values_1,\n",
    "                    \"y\": feature_x_sample_signal_1.loc[sign_feature, values_1.index],\n",
    "                    \"text\": values_1.index,\n",
    "                    \"mode\": \"markers\",\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:52.556033Z",
     "start_time": "2018-07-06T07:59:52.348450Z"
    }
   },
   "outputs": [],
   "source": [
    "h_1 = ccal.solve_for_H(feature_x_sample_signal_1.fillna(0), w_0, method=\"nnls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T07:59:52.556033Z",
     "start_time": "2018-07-06T07:59:52.348450Z"
    }
   },
   "outputs": [],
   "source": [
    "title = \"{}<br>Infers<br>{}\".format(\n",
    "    SETTING[\"feature_x_sample_alias\"], SETTING[\"new_feature_x_sample_alias\"]\n",
    ")\n",
    "\n",
    "h_element_states_1 = gps_map_0.predict(\n",
    "    \"h\",\n",
    "    h_1,\n",
    "    n_pull=SETTING[\"gps_map_h_n_pull\"],\n",
    "    pull_power=SETTING[\"gps_map_h_pull_power\"],\n",
    "    element_marker_size=32,\n",
    "    title=title,\n",
    "    html_file_path=os.path.join(PATH[\"infer/\"], \"gps_map.html\"),\n",
    ")\n",
    "\n",
    "ccal.plot_heat_map(\n",
    "    h_1,\n",
    "    column_annotation=h_element_states_1,\n",
    "    title=title,\n",
    "    xaxis_title=h_1.columns.name,\n",
    "    yaxis_title=h_1.index.name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
